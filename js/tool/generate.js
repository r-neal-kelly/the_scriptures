var __awaiter=this&&this.__awaiter||function(e,t,n,_){return new(n||(n=Promise))((function(s,o){function a(e){try{r(_.next(e))}catch(e){o(e)}}function i(e){try{r(_.throw(e))}catch(e){o(e)}}function r(e){var t;e.done?s(e.value):(t=e.value,t instanceof n?t:new n((function(e){e(t)}))).then(a,i)}r((_=_.apply(e,t||[])).next())}))};import*as process from"process";import*as Utils from"../utils.js";import*as Unicode from"../unicode.js";import*as Compressor from"../compressor.js";import*as Language from"../model/language.js";import*as Data from"../model/data.js";import*as Text from"../model/text.js";import*as File_System from"./file_system.js";const TIMESTAMP_PATH="./.timestamp",README_PATH="./README.md",DEFAULT_LAST_TIMESTAMP=0,IS_COMPRESSED_FILE_REGEX=new RegExp(`\\.${Data.Consts.FILE_EXTENSION}$`);class Unique_Parts{constructor(){this.parts={}}Add(e){this.parts.hasOwnProperty(e)?(0,this.parts[e]+=1):this.parts[e]=1}Values(){return Object.keys(this.parts).sort(function(e,t){return this.parts[t]-this.parts[e]}.bind(this))}Count(e){return 0,this.parts[e]}}class Line_Language{constructor(e){this.default_language_name=e,this.part_counts=Object.create(null),this.total_part_count=0}Add_Part(e){if(!e.Is_Command()){const t=e.Language()||this.default_language_name;null==this.part_counts[t]&&(this.part_counts[t]=0),this.part_counts[t]+=1,this.total_part_count+=1}}Result(){const e=Object.entries(this.part_counts).map(function(e){return[e[0],100*e[1]/this.total_part_count]}.bind(this));return e.sort((function(e,t){return t[1]-e[1]})),e.length>0?e[0][0]:this.default_language_name}}function Read_And_Sort_File_Names(e){return __awaiter(this,void 0,void 0,(function*(){const t=(yield File_System.File_Names(e)).filter((function(e){return/\.txt$/.test(e)&&!/COPY\.txt$/.test(e)}));if(File_System.Has_File(`${e}/${Data.Consts.ORDER_JSON_NAME}`)){const n=JSON.parse(yield File_System.Read_File(`${e}/${Data.Consts.ORDER_JSON_NAME}`)),_=[];for(const e of t)n.includes(e)||_.push(e);return Utils.Assert_Even_In_Release(0===_.length,`${e}/${Data.Consts.ORDER_JSON_NAME} is missing various files:\n${JSON.stringify(_)}`),n}return t.sort()}))}function Read_Dictionary_And_Files(e,t,n){return __awaiter(this,void 0,void 0,(function*(){const _=new Text.Dictionary.Instance({json:yield File_System.Read_File(`${e}/${Data.Consts.DICTIONARY_JSON_NAME}`)}),s=[],o=[];let a=_.Maybe_Validation_Error();Utils.Assert_Even_In_Release(null==a,`Dictionary failed to validate: ${a}`),_.Set_Default_Language_Name(n);for(const n of t){const t=yield Read_File_Value(`${e}/${n}`);s.push(t),o.push(new Text.Instance({dictionary:_,value:t}))}_.Reset_With(o),o.splice(0,o.length),a=_.Maybe_Validation_Error(),Utils.Assert_Even_In_Release(null==a,`Dictionary failed to validate: ${a}`),0;for(const e of s)o.push(new Text.Instance({dictionary:_,value:e}));return[_,s,o]}))}function Read_File_Value(e){return __awaiter(this,void 0,void 0,(function*(){const t=yield File_System.Read_And_Write_File_With_No_Carriage_Returns(e);return Utils.Assert_Even_In_Release(Language.Greek.Normalize_With_Combined_Points(Language.Greek.Normalize_With_Baked_Points(t))===t,`\n            Failed to reproduce original file_value after Greek normalization!\n            ${t}\n        `),t}))}function Should_Version_Be_Updated(e,t,n){return __awaiter(this,void 0,void 0,(function*(){for(const n of[`${t}/${Data.Consts.INFO_JSON_NAME}`,`${t}/${Data.Consts.DICTIONARY_JSON_NAME}`,`${t}/${Data.Consts.UNIQUE_PARTS_NAME}`])if(!File_System.Has_File(n)||(yield File_System.Read_Entity_Last_Modified_Time(n))>e)return!0;if(File_System.Has_File(`${t}/${Data.Consts.ORDER_JSON_NAME}`)&&(yield File_System.Read_Entity_Last_Modified_Time(`${t}/${Data.Consts.ORDER_JSON_NAME}`))>e)return!0;for(const _ of n){const n=`${t}/${_.replace(/\.[^.]*$/,`.${Data.Consts.FILE_EXTENSION}`)}`;if(!File_System.Has_File(n)||(yield File_System.Read_Entity_Last_Modified_Time(`${t}/${_}`))>e||(yield File_System.Read_Entity_Last_Modified_Time(n))>e)return!0}return!1}))}function Delete_Compiled_Files(e){return __awaiter(this,void 0,void 0,(function*(){const t=(yield File_System.File_Names(e)).filter((function(e){return IS_COMPRESSED_FILE_REGEX.test(e)}));yield Promise.all(t.map((t=>File_System.Delete_File(`${e}/${t}`))))}))}function Decompression_Line_Mismatches(e,t){const n=e.split(/\r?\n/),_=t.split(/\r?\n/);let s="";for(let e=0,t=n.length;e<t;e+=1)e<_.length?n[e]!==_[e]&&(s+=`${e}: ${n[e]} !== ${_[e]}\n`):s+=`${e}: <missing line>\n`;return""===s?"<no mismatching lines>":s}function Interlineate(){return __awaiter(this,void 0,void 0,(function*(){}))}function Generate(e){return __awaiter(this,void 0,void 0,(function*(){const t=e?0:File_System.Has_File("./.timestamp")?yield File_System.Read_Entity_Last_Modified_Time("./.timestamp"):0,n=new Data.Info.Instance({});0===t?console.log("    Forcefully generating all files..."):console.log("    Only generating out-of-date files..."),yield function(){return __awaiter(this,void 0,void 0,(function*(){const e=Data.Consts.BOOKS_PATH;for(const _ of(yield File_System.Folder_Names(e)).sort()){const s=`${e}/${_}`,o={name:_,languages:[]};n.Tree().books.push(o),n.Add_Unique_Book_Name(_);for(const e of(yield File_System.Folder_Names(s)).sort()){const a=`${s}/${e}`,i={name:e,versions:[]};o.languages.push(i),n.Add_Unique_Language_Name(e);for(const s of(yield File_System.Folder_Names(a)).sort()){const o=`${a}/${s}`,r=yield Read_And_Sort_File_Names(o),l={name:s,files:r.map(Utils.Remove_File_Extension)};if(i.versions.push(l),n.Add_Unique_Version_Name(s),yield Should_Version_Be_Updated(t,o,r)){const t=new Data.Version.Info.Instance({}),[n,a,i]=yield Read_Dictionary_And_Files(o,r,e),l=new Unique_Parts;t.Increment_File_Count(e,r.length),yield Delete_Compiled_Files(o);for(let n=0,o=r.length;n<o;n+=1){const o=i[n];t.Update_Buffer_Counts(o);for(let a=0,i=o.Line_Count();a<i;a+=1){const i=o.Line(a),u=new Line_Language(e);for(let o=0,c=i.Column_Count();o<c;o+=1){const c=i.Column(o);for(let i=0,d=c.Row_Count();i<d;i+=1){const d=c.Row(i);for(let c=0,m=d.Macro_Part_Count();c<m;c+=1){const m=d.Macro_Part(c),g=m.Part_Type(),C=m.Value(),f=C.length,$=Unicode.Point_Count(C),p=m.Language()?m.Language():e;if(Utils.Assert_Even_In_Release(!m.Is_Unknown(),`Unknown part! Cannot generate:\n   Book Name:          ${_}\n   Language Name:      ${e}\n   Version Name:       ${s}\n   File Name:          ${r[n]}\n   Line Index:         ${a}\n   Column Index:       ${o}\n   Row Index:          ${i}\n   Macro Part Index:   ${c}\n   Macro Part Value:   ${C}\n`),m.Is_Error()&&Utils.Assert_Even_In_Release(m.Has_Error_Style(),`Error not wrapped with fix command! Should not generate:\n   Book Name:          ${_}\n   Language Name:      ${e}\n   Version Name:       ${s}\n   File Name:          ${r[n]}\n   Line Index:         ${a}\n   Column Index:       ${o}\n   Row Index:          ${i}\n   Macro Part Index:   ${c}\n   Macro Part Value:   ${C}\n`),l.Add(C),u.Add_Part(m),t.Increment_Unit_Count(p,f),t.Increment_Point_Count(p,$),g===Text.Part.Type.LETTER)t.Increment_Letter_Count(p,1),t.Increment_Part_Count(p,1);else if(g===Text.Part.Type.MARKER)t.Increment_Marker_Count(p,1),t.Increment_Part_Count(p,1);else if(g===Text.Part.Type.WORD)t.Increment_Letter_Count(p,$),t.Increment_Word_Count(p,1),t.Increment_Part_Count(p,1);else if(g===Text.Part.Type.BREAK)t.Increment_Marker_Count(p,$),t.Increment_Break_Count(p,1),t.Increment_Part_Count(p,1);else if(g===Text.Part.Type.COMMAND){const e=m;t.Increment_Meta_Letter_Count(p,$),e.Is_Last_Of_Split()||(t.Increment_Meta_Word_Count(p,1),t.Increment_Part_Count(p,1))}}}}t.Increment_Line_Count(u.Result(),1)}}const u=[],c=l.Values(),d=JSON.stringify(c),m=Compressor.LZSS_Compress(d),g=Compressor.LZSS_Decompress(m),C=new Data.Version.Compressor.Instance({unique_parts:c}),f=new Data.Version.Decompressor.Instance({unique_parts:c}),$=n.To_JSON(),p=C.Compress_Dictionary({dictionary_value:$}),y=f.Decompress_Dictionary({dictionary_value:p}),S=[];Utils.Assert_Even_In_Release(g===d,"Invalid unique_part_values_json decompression!"),Utils.Assert_Even_In_Release(y===$,"Invalid dictionary decompression!"),t.Finalize(),u.push(File_System.Write_File(`${o}/${Data.Consts.INFO_JSON_NAME}`,t.JSON_String())),u.push(File_System.Write_File(`${o}/${Data.Consts.UNIQUE_PARTS_NAME}`,m)),u.push(File_System.Write_File(`${o}/${Data.Consts.DICTIONARY_JSON_NAME}`,$)),u.push(File_System.Write_File(`${o}/${Data.Consts.DICTIONARY_NAME}`,p));for(let t=0,i=r.length;t<i;t+=1){const i=r[t],l=a[t],c=C.Compress_File({dictionary:n,file_value:l}),d=f.Decompress_File({dictionary:n,file_value:c});Utils.Assert_Even_In_Release(d===l,`Invalid decompression!\n   Book Name: ${_}\n   Language Name: ${e}\n   Version Name: ${s}\n   File Name: ${i}\n${Decompression_Line_Mismatches(l,d)}`),S.push(c),u.push(File_System.Write_File(`${o}/${i.replace(/\.[^.]*$/,`.${Data.Consts.FILE_EXTENSION}`)}`,c))}const I=S.join(Data.Consts.VERSION_TEXT_FILE_BREAK);u.push(File_System.Write_File(`${o}/${Data.Consts.VERSION_TEXT_NAME}`,I)),yield Promise.all(u),console.log(`        Generated ${_}/${e}/${s}...`)}const u=new Data.Version.Info.Instance({json:yield File_System.Read_File(`${o}/${Data.Consts.INFO_JSON_NAME}`)});n.Increment_Unit_Counts(u.Language_Unit_Counts()),n.Increment_Point_Counts(u.Language_Point_Counts()),n.Increment_Letter_Counts(u.Language_Letter_Counts()),n.Increment_Marker_Counts(u.Language_Marker_Counts()),n.Increment_Meta_Letter_Counts(u.Language_Meta_Letter_Counts()),n.Increment_Word_Counts(u.Language_Word_Counts()),n.Increment_Break_Counts(u.Language_Break_Counts()),n.Increment_Meta_Word_Counts(u.Language_Meta_Word_Counts()),n.Increment_Part_Counts(u.Language_Part_Counts()),n.Increment_Line_Counts(u.Language_Line_Counts()),n.Increment_File_Counts(u.Language_File_Counts()),n.Increment_Book_Count(e,1),n.Update_Max_File_Count(u.Total_File_Count()),n.Update_Buffer_Counts(u)}}}n.Finalize();const _=n.JSON_String(),s=Compressor.LZSS_Compress(_),o=Compressor.LZSS_Decompress(s);Utils.Assert_Even_In_Release(o===_,"LZSS failed to decompress data_info_json"),yield File_System.Write_File(Data.Consts.INFO_PATH,s)}))}(),yield function(){return __awaiter(this,void 0,void 0,(function*(){let e=yield File_System.Read_File(README_PATH);const t="## Stats";let _=null,s=null;for(let i=0,r=e.length;i<r;i+=1){const l=e.slice(i);null===_?l.slice(0,8)===t&&(_=i):null===s&&"##"===l.slice(0,2)&&(s=i)}if(null!==_){function o(e,t){let n="";for(const _ of t)n+=`${e}    - ${_}\n`;return n}function a(e,t){let n="";for(const[_,s,o]of t)n+=`${e}    - ${_}: ${Utils.Add_Commas_To_Number(s)} (~${o}%)\n`;return n}null===s&&(s=e.length),e=e.slice(0,_)+"## Stats\n\n"+`- Unique Languages: ${n.Unique_Language_Name_Count_String()}\n`+o("",n.Unique_Language_Names())+`- Unique Versions: ${n.Unique_Version_Name_Count_String()}\n`+o("",n.Unique_Version_Names())+`- Unique Books: ${n.Unique_Book_Name_Count_String()}\n`+o("",n.Unique_Book_Names())+"\n<br>\n\n"+`- Total Books: ${n.Total_Book_Count_String()}\n`+a("",n.Language_Book_Counts_And_Percents())+`- Total Files: ${n.Total_File_Count_String()}\n`+a("",n.Language_File_Counts_And_Percents())+`- Total Lines: ${n.Total_Line_Count_String()}\n`+a("",n.Language_Line_Counts_And_Percents())+`- Total Parts: ${n.Total_Part_Count_String()}\n    - <i>By Language</i>\n`+a("    ",n.Language_Part_Counts_And_Percents())+"    - <i>By Components</i>\n"+`        - Words: ${n.Total_Word_Count_String()} (~${n.Total_Word_Percent()}%)\n`+a("        ",n.Language_Word_Counts_And_Percents())+`        - Meta-Words: ${n.Total_Meta_Word_Count_String()} (~${n.Total_Meta_Word_Percent()}%)\n`+a("        ",n.Language_Meta_Word_Counts_And_Percents())+`        - Non-Words: ${n.Total_Break_Count_String()} (~${n.Total_Break_Percent()}%)\n`+a("        ",n.Language_Break_Counts_And_Percents())+`- Total Unicode Points: ${n.Total_Point_Count_String()}\n    - <i>By Language</i>\n`+a("    ",n.Language_Point_Counts_And_Percents())+"    - <i>By Components</i>\n"+`        - Letters: ${n.Total_Letter_Count_String()} (~${n.Total_Letter_Percent()}%)\n`+a("        ",n.Language_Letter_Counts_And_Percents())+`        - Meta-Letters: ${n.Total_Meta_Letter_Count_String()} (~${n.Total_Meta_Letter_Percent()}%)\n`+a("        ",n.Language_Meta_Letter_Counts_And_Percents())+`        - Non-Letters: ${n.Total_Marker_Count_String()} (~${n.Total_Marker_Percent()}%)\n`+a("        ",n.Language_Marker_Counts_And_Percents())+e.slice(s,e.length)}yield File_System.Write_File(README_PATH,e)}))}(),yield File_System.Write_File("./.timestamp","")}))}!function(){__awaiter(this,void 0,void 0,(function*(){const e=process.argv.slice(2);yield Generate(e.includes("-f")||e.includes("--force"))}))}();